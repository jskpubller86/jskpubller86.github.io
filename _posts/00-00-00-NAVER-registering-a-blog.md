---
title : Naver 검색엔진에 블로그 등록하기
date: 2025-07-16
categories : naver
---


네이버에 검색엔진에서 내 블로그의 글을 잘 수집할 수 있도록 하기 위해서는 내 블로그의 페이지 수집 상태를 관리해야 한다.

이를 위해 네이버 웹마스터를 사용할 수 있으며 sitemap, rss 등을 제공함으로써 로봇이 페이지 수집하는데 있어 도움을 줄 수 있다.

그리고 이러한 행위를 최적화라고 한다.

## 1. 네이버 웹마스터 활성화

내 사이트가 검색 최적화에 문제가 없는지 확인하기 위해서 웹마스터에 내 사이트를 등록해야한다.

네이버 검색 어드마이저(<https://searchadvisor.naver.com/>)로 이동한다.

네이버 아이디로 로그인한다.

혹시 `네이버 서치어드바이저 이용 동의` 화면이 나오면 동의한다.

웹마스터 도구 페이지로 이동 후 사이트 등록 양식에서 현재 사용 중인 깃 블로그의 주소를 입력하여 추가한다. 

그 후 빨간색 표시에 있는 버튼을 클릭하여 사이트 소유 확인 페이지로 이동한다.

![사이트 등록 페이지](/assets/images/naver/webmaster.PNG)

사이트 소유 확인 페이지에서 `1. HTML 확인 파일을 다운로드 합니다.` 부분에 있는 `HTML 확인 파일`을 클릭하여 파일 내려받고 블로그의 루트(ROOT)에 파일을 올린다.

![사이트 등록 페이지2](/assets/images/naver/webmaster2.PNG)

파일을 올린 후 3번에 있는 링크를 클릭하여 정상적으로 반영되었는지 확인한다.

연결되면 다음과 비슷한 화면이 나온다.

![사이트 등록 페이지3](/assets/images/naver/webmaster3.PNG)


반영 후에 링크까지 확인하였다면 소유확인 버튼을 클릭하여 소유확인을 진행한다.


소유확인이 끝나면 간단체크 페이지로 이동하여 내 블로그를 검사해본다.

![사이트 등록 페이지2](/assets/images/naver/webmaster4.PNG)


검사에서 내 블로그 같은 경우에는 `robots.txt가 존재하지 않습니다.` 경고를 확인할 수 있다. 

이를 해결하기 위해서 옆에 `네이버 로봇 차단 설정/변경` 링크를 클릭한다. 

클릭하면 `robots.txt 설정하기` 페이지로 이동한다. 

robots.txt 파일은 로봇이 내 블로그의 정보를 수집할 때 여러 규칙을 설정할 수 있다. 

일반적으로 규칙이 없다면 내 블로그의 모든 정보를 수집한다.

나의 같은 경우는 다음과 같이 설정했다. 

```
User-agent: *
Allow: /
Sitemap : https://jskpubller86.github.io/sitemap.xml
```

- `User-agent: *` : 모든 로봇을 허용한다.
- `Allow: /` : 모든 페이지 수집을 허용한다.
- `Sitemap: https://jskpubller86.github.io/sitemap.xml` : 로봇에게 사이트 맵의 주소를 알려준다.

작성하고 나서 루트(ROOT)에 올립니다.

반영 후에 재검사를 하면 `robots.txt`를 올바르게 인식하고 있음을 볼 수 있다.

## 2. 사이트맵(Sitemap) 제출

검색엔진 로봇은 페이지를 수집하여 색인을 만듭니다. 이 과정에서 색인이 올바르게 생성되어야 페이지가 잘 노출될 수 있다.

이때 사이트에 대한 구조를 알려주면 색인을 만들 때 도움이 될 수 있다. 

또한 '콘텐츠 피드'로 간주하여 주기적으로 사이트를 재방문합니다.

이를 위해 `Sitemap.xml` 파일 형태로 제공한다. 

나의 경우 `robots.txt` 파일에 `Sitemap: https://jskpubller86.github.io/sitemap.xml` 형식으로 설정하여 sitemap을 제공하였다.

sitemap.xml 파일을 생성하는 방법에는 여러가지가 있다.

나의 경우에는 jekyll을 이용한 블로그이므로 `jekyll-sitemap` 플러그인을 사용하여 생성한다.

다른 방법으로는 사이트맵(Sitemap)을 생성하는 사이트를 이용할 수 있다. 

여러 사이트가 있지만 그 중에 한 곳을 소개한다. 

<https://www.xml-sitemaps.com/>

## 3. RSS 제출

RSS(Rich Site Summary)란 내 사이트의 콘테츠 정보를 다른 곳에서 받아 해당 콘텐츠 정보를 노출하는 것을 말한다.

이에 따라 내 사이트의 입장하지 않아도 RSS를 받는 다른 사이트에서 내 사이트의 콘텐츠를 볼 수 있다.

뉴스나 블로그가  대표적인 예시이다.

RSS를 제출하면 로봇이 콘텐츠를 수집하는데 도움된다.

또한 사이트맵(Sitemap)과 마찬가지로 '콘텐츠 피드'로 간주하여 주기적으로 사이트를 재방문한다.

보통 `feed.xml` 파일로 제공한다.

내 블로그는 `jekyll-feed` 플러그인을 사용하여 `feed.xml` 파일을 만든다.

그러나 위 방식은 Atom 포맷을 사용한다.

네이버 검색엔진은 RSS 포맷을 허용한다.

그러므로 jekyll 블로그의 경우 인터넷에 떠도는 RSS 생성 코드를 이용한다.

참고로 네이버에서는 RSS보다 Simtemap을 권장한다.

이유는 Sitemap은 링크로 이루어져 있어 콘텐츠가 포함된 RSS보다 더 많은 페이지 수집 정보를 제공할 수 있기 때문이다.



=끝=

















